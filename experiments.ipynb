{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_absolute_error as mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions related to the model\n",
    "(i.e. k-fold cv, running the model, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cs(gt, pred, alpha):\n",
    "    \"\"\"\n",
    "    Computes the Cumulative Score with given alpha\n",
    "\n",
    "    :param gt:    Ground truths\n",
    "    :param pred:  Predicted dates\n",
    "    :param alpha: Acceptable error range in years\n",
    "\n",
    "    :return: The CS with given alpha\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for i in range(len(gt)):\n",
    "        absolute_error = abs(gt[i] - pred[i])\n",
    "        if absolute_error <= alpha:\n",
    "            count += 1\n",
    "\n",
    "    return count / len(gt) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_cv(model, features, labels, k, seed):\n",
    "    \"\"\"\n",
    "    Performs stratisfied k-fold cross-validation.\n",
    "\n",
    "    :param model:    The model to train\n",
    "    :param features: Features to train and test the model with\n",
    "    :param labels:   Labels of the features\n",
    "    :param k:        Number of folds for the cross-validation\n",
    "    :param seed:     Seed for splitting data into test/train sets\n",
    "\n",
    "    :return: Mean and SD of MAE, CS with alpha = 25 and alpha = 0 years across all folds.\n",
    "    \"\"\"\n",
    "    mae_k = []\n",
    "    cs_k = []\n",
    "    cs_1 = []\n",
    "    # As the dataset is imbalanced --> stratified kfold + seed to get the same validation/train splits\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=seed)\n",
    "\n",
    "    for train_index, test_index in kf.split(features, labels):\n",
    "        # Getting test and train sets\n",
    "        train_features, test_features = features[train_index], features[test_index]\n",
    "        train_labels, test_labels = [labels[i] for i in train_index], [labels[i] for i in test_index]\n",
    "\n",
    "        # Training model and predicting dates on test data\n",
    "        model.fit(train_features, train_labels)\n",
    "        pred = model.predict(test_features)\n",
    "        pred = [int(i) for i in pred]\n",
    "\n",
    "        mae_k.append(mae(test_labels, pred))\n",
    "        cs_k.append(cs(test_labels, pred, 25))\n",
    "        cs_1.append(cs(test_labels, pred, 0))\n",
    "\n",
    "    return np.mean(mae_k), np.std(mae_k), np.mean(cs_k), np.std(cs_k), np.mean(cs_1), np.std(cs_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def kfold_cv_aug(model, features_norm, features_aug, labels_norm, labels_aug, k, n_aug, seed):\n",
    "    \"\"\"\n",
    "    Performs stratisfied k-fold cross-validation for augmented data.\n",
    "\n",
    "    :param model:         The model to train\n",
    "    :param features_norm: Features of non-augmented images\n",
    "    :param features_aug:  Features of augmented images\n",
    "    :param labels_norm:   Labels of the non-augmented features\n",
    "    :param labels_aug:    Labels of the augmented features\n",
    "    :param k:             Number of folds for the cross-validation\n",
    "    :param n_aug:         Number of augmented images per non-augmented image\n",
    "    :param seed:          Seed for splitting data into test/train sets\n",
    "\n",
    "    :return: Mean and SD of MAE, CS with alpha = 25 and alpha = 0 years across all folds.\n",
    "    \"\"\"\n",
    "    mae_k = []\n",
    "    cs_k = []\n",
    "    cs_1 = []\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=seed)\n",
    "    for train_index, test_index in tqdm.tqdm(kf.split(features_norm, labels_norm)):\n",
    "        # Getting test and train sets from non-augmented labels and features\n",
    "        test = [features_norm[idx] for idx in test_index]\n",
    "        test_labels = [labels_norm[idx] for idx in test_index]\n",
    "\n",
    "        train = [features_norm[idx] for idx in train_index]\n",
    "        train_labels = [labels_norm[idx] for idx in train_index]\n",
    "\n",
    "        # Getting test and training sets from augmented labels and features\n",
    "        for idx in range(len(features_aug)):\n",
    "            if int(idx/n_aug) in test_index:\n",
    "                continue\n",
    "            else:\n",
    "                train.append(features_aug[idx])\n",
    "                train_labels.append(labels_aug[idx])\n",
    "\n",
    "        # Training the model and predicting dates\n",
    "        model.fit(train, train_labels)\n",
    "        pred = model.predict(test)\n",
    "        pred = [int(i) for i in pred]\n",
    "\n",
    "        mae_k.append(mae(test_labels, pred))\n",
    "        cs_k.append(cs(test_labels, pred, 25))\n",
    "        cs_1.append(cs(test_labels, pred, 0))\n",
    "    return np.mean(mae_k), np.std(mae_k), np.mean(cs_k), np.std(cs_k), np.mean(cs_1), np.std(cs_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(model, train_features, test_features, train_labels, test_labels):\n",
    "    \"\"\"\n",
    "    Predicts dates with a given model.\n",
    "\n",
    "    :param model:          The model to train\n",
    "    :param train_features: Features to train the model witb\n",
    "    :param test_features:  Features to test the model with\n",
    "    :param train_labels:   Labels of train features\n",
    "    :param test_labels:    Labels of test features\n",
    "\n",
    "    :return: Mean Absolute Error (MAE) and Cumulative Score with alpha-values 25 and 0\n",
    "    \"\"\"\n",
    "    model.fit(train_features, train_labels)\n",
    "    pred = model.predict(test_features)\n",
    "    pred = [int(i) for i in pred]\n",
    "    return round(mae(test_labels, pred), 4), round(cs(test_labels, pred, 25), 4), round(cs(test_labels, pred, 1), 4)\n",
    "\n",
    "def plot_model(model, train_features, test_features, train_labels, test_labels):\n",
    "    \"\"\"\n",
    "    Predicts dates with a given model and displays a scatter plot of \n",
    "    the ground truth and predicted dates.\n",
    "\n",
    "    :param model:          The model to train\n",
    "    :param train_features: Features to train the model witb\n",
    "    :param test_features:  Features to test the model with\n",
    "    :param train_labels:   Labels of train features\n",
    "    :param test_labels:    Labels of test features\n",
    "\n",
    "    :return: Mean Absolute Error (MAE) and Cumulative Score with alpha-values 25 and 0\n",
    "    \"\"\"\n",
    "    model.fit(train_features, train_labels)\n",
    "    pred = model.predict(test_features)\n",
    "    pred = [int(i) for i in pred]\n",
    "\n",
    "    plt.scatter(test_labels, pred)\n",
    "    plt.ylabel('pred')\n",
    "    plt.xlabel('true')\n",
    "    plt.show()\n",
    "    return round(mae(test_labels, pred), 4), round(cs(test_labels, pred, 25), 4), round(cs(test_labels, pred, 1), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to process the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "HINGE = 0\n",
    "JUNC = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_features(features):\n",
    "    \"\"\"\n",
    "    Rescales features between 0 and 1\n",
    "    \"\"\"\n",
    "    features = np.asarray(features)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(features)\n",
    "    data_rescaled = scaler.transform(features)\n",
    "\n",
    "    return data_rescaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_features_split(features1, features2):\n",
    "    \"\"\"\n",
    "    Rescales features between 0 and 1 in the case of 2 split sets of features    \n",
    "    \"\"\"\n",
    "    features1 = np.array(features1)\n",
    "    features2 = np.array(features2)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(np.concatenate((features1, features2), axis=0))\n",
    "    data_rescaled1 = scaler.transform(features1)\n",
    "    data_rescaled2 = scaler.transform(features2)\n",
    "    return data_rescaled1, data_rescaled2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features2(feature_dir, hinge_or_junc, n_aug):\n",
    "    \"\"\"\n",
    "    Reads feature vectors from files in a directory\n",
    "\n",
    "    :param feature_dir:   Directory containing feature files\n",
    "    :param hinge_or_junc: Boolean value whether feature is from Hinge family (0) \n",
    "                          or is the Junclets feature (1)\n",
    "    :param n_aug:         Number of augmented images per non-augmented image\n",
    "\n",
    "    :return: List of feature vectors and corresponding labels (key years)\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "    count = 0\n",
    "    print(n_aug, feature_dir)\n",
    "\n",
    "    # Iterating over all feature files\n",
    "    for file in sorted(os.listdir(feature_dir)):\n",
    "        aug_num = re.search(\"(_[0-9]?[0-9].p)\", file)\n",
    "\n",
    "        if aug_num is not None:\n",
    "            aug_num = re.search(\"([0-9]?[0-9])\", aug_num.group())\n",
    "        if aug_num is None or (aug_num is not None and int(aug_num.group()) <= n_aug):\n",
    "            if file != \".DS_Store\" and not os.path.isdir(feature_dir + '/' + file):\n",
    "                f = open(feature_dir + \"/\" + file)\n",
    "                # Gets the file's feature vector\n",
    "                for line in f.readlines():\n",
    "                    line = line.rstrip().split(\" \")\n",
    "                    if hinge_or_junc == HINGE:\n",
    "                        features.append(line[2:])\n",
    "                    elif hinge_or_junc == JUNC:\n",
    "                        features.append([float(el) for el in line])\n",
    "                        count += 1\n",
    "\n",
    "                    label = re.search(\"([0-9][0-9][0-9][0-9])\", file) #MPS\n",
    "                    #label = re.search(\"(-?[0-9][0-9][0-9])\", file) #DSS\n",
    "                    labels.append(int(label.group()))\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(featuredir, size, n_aug):\n",
    "    \"\"\"\n",
    "    Returns features and labels in a directory\n",
    "    \"\"\"\n",
    "    if featuredir != 'junclets' and featuredir != 'test/junclets':\n",
    "        prefix = './Data/DSS/features/'   # Change with data set used\n",
    "        features, labels = get_features2(prefix + featuredir, HINGE, n_aug)\n",
    "    elif featuredir == 'junclets':\n",
    "        prefix = './Data/DSS/features/' + featuredir + '/size_' + str(size) + '/'  # Change with data set used\n",
    "        features, labels = get_features2(prefix, JUNC, n_aug)\n",
    "    return features, labels\n",
    "\n",
    "def get_features_aug(featuredir, size, n_aug):\n",
    "    \"\"\"\n",
    "    Returns features and labels in a directory of both non-augmented and augmented images\n",
    "    \"\"\"\n",
    "    if featuredir != 'junclets':\n",
    "        prefix = './Data/DSS/features/' # Change with data set used\n",
    "        features_norm, labels_norm = get_features2(prefix + featuredir, HINGE, n_aug)\n",
    "        prefix = prefix + 'features_aug_15/' + featuredir + '_aug'          # Change with data set used\n",
    "        features_aug, labels_aug = get_features2(prefix, HINGE, n_aug)\n",
    "    else:\n",
    "        prefix = './Data/DSS/features/junclets/size_' + str(size) + '/'      # Change with data set used\n",
    "        features_norm, labels_norm = get_features2(prefix, JUNC, n_aug)\n",
    "        prefix = './Data/DSS/features/junclets_aug/size_' + str(size) + '/'  # Change with data set used\n",
    "        features_aug, labels_aug = get_features2(prefix, JUNC, n_aug)\n",
    "\n",
    "    return features_norm, labels_norm, features_aug, labels_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting indices for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MPS\n",
    "size_data = 3267\n",
    "test_size = 0.1 #as a fraction\n",
    "test_indices = np.random.choice(np.array([i for i in range(size_data)]), int(size_data * test_size), replace=False)\n",
    "np.save('./test_indices.npy', test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EA and DSS\n",
    "idx = 0\n",
    "for file in sorted(os.listdir('./Data/DSS/DSS_jpg_re/')):\n",
    "    label = re.search(\"(-?[0-9][0-9][0-9])\", file)\n",
    "    print(label.group(), idx)\n",
    "    idx += 1\n",
    "\n",
    "np.save('./Data/DSS/test_indices.npy', [0, 5, 6, 16, 17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = np.load('./Data/DSS/test_indices.npy')\n",
    "#test_indices = np.load('./tfsom/MPS/test_indices.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Hyperparameters\n",
    "Uses K-fold cross validation with k = 10 for MPS and k = 4 for EA and DSS data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "With original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Hinge features\n",
    "\n",
    "feat_names = ['hinge', 'cohinge', 'quadhinge', 'deltahinge', 'tcchinge']\n",
    "\n",
    "k = 4    # EA and DSS number of folds in cross-validation\n",
    "# k = 10 # MPS number of folds in cross-validation\n",
    "Cs = [pow(2, n) for n in range(-7, 10, 1)]  # hyper-parameter range of values\n",
    "seeds = [0, 50, 100, 150, 200, 250]\n",
    "\n",
    "# Iterates over all features\n",
    "for featuredir in feat_names:\n",
    "    print(featuredir)\n",
    "\n",
    "    # Getting the feature vectors and labels\n",
    "    features, labels = get_features(featuredir, 0, 0)\n",
    "    features = rescale_features(features)\n",
    "\n",
    "    # Getting the test set\n",
    "    test = [features[idx] for idx in test_indices]\n",
    "    test_labels = [labels[idx] for idx in test_indices]\n",
    "\n",
    "    # Getting the train set\n",
    "    train = []\n",
    "    train_labels = []\n",
    "    for idx in range(len(features)):\n",
    "        if idx not in test_indices:\n",
    "            train.append(features[idx])\n",
    "            train_labels.append(labels[idx])\n",
    "\n",
    "    results = [[0, 0, 0, 0, 0, 0, 0] for i in range(len(Cs))]\n",
    "\n",
    "    # k-fold cross validation for all seeds and hyper-parameter values\n",
    "    for seed in seeds:\n",
    "        for c_idx in range(len(Cs)):\n",
    "            results[c_idx][0] = Cs[c_idx]\n",
    "            clf = kfold_cv(svm.SVC(kernel='linear', decision_function_shape='ovr', C=Cs[c_idx]), np.array(train), np.array(train_labels), k, seed)\n",
    "            for res_idx in range(len(clf)):\n",
    "                results[c_idx][res_idx + 1] += clf[res_idx]\n",
    "    \n",
    "    # Computing mean results across seeds\n",
    "    for c_idx in range(len(results)):\n",
    "        for res_idx in range(1, len(results[c_idx])):\n",
    "            results[c_idx][res_idx] = results[c_idx][res_idx]/len(seeds)\n",
    "\n",
    "    for res in results:\n",
    "        print(res)\n",
    "    np.save('./Data/DSS/validation_' + featuredir + '.npy', results) ## Change according to data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# For the Junclets feature\n",
    "\n",
    "featuredir = 'junclets'\n",
    "\n",
    "k = 4   # EA and DSS number of folds for cross-validation\n",
    "# k = 10 # MPS number of folds for cross-validation\n",
    "Cs = [pow(2, n) for n in range(-7,10, 1)]\n",
    "seeds = [0, 50, 100, 150, 200, 250]\n",
    "\n",
    "# Iterates over all sub-codebook sizes\n",
    "for cb_size in range(5, 35, 5):\n",
    "    print(cb_size)\n",
    "    # Getting the feature vectors and labels\n",
    "    features, labels = get_features(featuredir, cb_size, 0)\n",
    "    features = rescale_features(features)\n",
    "\n",
    "    # Getting the test set\n",
    "    test = [features[idx] for idx in test_indices]\n",
    "    test_labels = [labels[idx] for idx in test_indices]\n",
    "\n",
    "    # Getting the train set\n",
    "    train = []\n",
    "    train_labels = []\n",
    "    for idx in range(len(features)):\n",
    "        if idx not in test_indices:\n",
    "            train.append(features[idx])\n",
    "            train_labels.append(labels[idx])\n",
    "\n",
    "    results = [[0, 0, 0, 0, 0, 0, 0] for i in range(len(Cs))]\n",
    "    # Cross-validation across all seeds and hyper-parameter values\n",
    "    for seed in seeds:\n",
    "        for c_idx in range(len(Cs)):\n",
    "            results[c_idx][0] = Cs[c_idx]\n",
    "            clf = kfold_cv(svm.SVC(kernel='linear', decision_function_shape='ovr', C=Cs[c_idx]), np.array(train), np.array(train_labels), k, seed)\n",
    "            for res_idx in range(len(clf)):\n",
    "                results[c_idx][res_idx + 1] += clf[res_idx]\n",
    "    \n",
    "    # Mean results across seeds\n",
    "    for c_idx in range(len(results)):\n",
    "        for res_idx in range(1, len(results[c_idx])):\n",
    "            results[c_idx][res_idx] = results[c_idx][res_idx]/len(seeds)\n",
    "\n",
    "    for res in results:\n",
    "        print(res)\n",
    "    np.save('./Data/DSS/validation_' + featuredir + '_' + str(cb_size) + '.npy', results) ## Change according to data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "With augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_names = ['hinge', 'cohinge', 'quadhinge', 'deltahinge', 'tcchinge', 'junclets']\n",
    "\n",
    "## EA and DSS\n",
    "# k = 4        # number of folds for cross-validation\n",
    "# n_aug = 15   # number of augmented images per non-augmented image\n",
    "# cb_size = 15 # size of codebook\n",
    "\n",
    "## MPS\n",
    "k = 10         # number of fold for cross-validation\n",
    "n_aug = 3      # number of augmented image per non-augmented image\n",
    "cb_size = 25   # size of codebook\n",
    "\n",
    "Cs = [pow(2, n) for n in range(-7,10, 1)] # range of values for hyper-parameter\n",
    "seeds = [0, 50, 100, 150, 200, 250]\n",
    "\n",
    "# Iterates over all features\n",
    "for featuredir in feat_names:\n",
    "    print(featuredir)\n",
    "    # Getting feature vectors and labels\n",
    "    features_norm, labels_norm, features_aug, labels_aug = get_features_aug(featuredir, cb_size, n_aug)\n",
    "    features_norm, features_aug = rescale_features_split(features_norm, features_aug)\n",
    "\n",
    "    # Getting test set\n",
    "    test = [features_norm[idx] for idx in test_indices]\n",
    "    test_labels = [labels_norm[idx] for idx in test_indices]\n",
    "\n",
    "    # Getting training set from the augmented feature vectors and labels\n",
    "    train_aug = []\n",
    "    train_aug_labels = []\n",
    "    for idx in range(len(features_aug)):\n",
    "        if int(idx/n_aug) in test_indices:\n",
    "            continue\n",
    "        else:\n",
    "            train_aug.append(features_aug[idx])\n",
    "            train_aug_labels.append(labels_aug[idx])\n",
    "\n",
    "    # Getting training set from the non-augmented feature vectors and labels\n",
    "    train_norm = []\n",
    "    train_norm_labels = []\n",
    "    for idx in range(len(features_norm)):\n",
    "        if idx not in test_indices:\n",
    "            train_norm.append(features_norm[idx])\n",
    "            train_norm_labels.append(labels_norm[idx])\n",
    "            \n",
    "    results = [[0, 0, 0, 0, 0, 0, 0] for i in range(len(Cs))]\n",
    "\n",
    "    # Cross validation across all seeds and hyper-parameter values\n",
    "    for seed in tqdm.tqdm(seeds):\n",
    "        print(seed)\n",
    "        for c_idx in range(len(Cs)):\n",
    "            print(Cs[c_idx])\n",
    "            results[c_idx][0] = Cs[c_idx]\n",
    "            clf = kfold_cv_aug(svm.SVC(kernel='linear', decision_function_shape='ovr', C=Cs[c_idx]), train_norm, train_aug, train_norm_labels, train_aug_labels, k, n_aug, seed=seed)\n",
    "            for res_idx in range(len(clf)):\n",
    "                results[c_idx][res_idx + 1] += clf[res_idx]\n",
    "    \n",
    "    # Mean results across seeds\n",
    "    for c_idx in range(len(results)):\n",
    "        for res_idx in range(1, len(results[c_idx])):\n",
    "            results[c_idx][res_idx] = results[c_idx][res_idx]/len(seeds)\n",
    "\n",
    "    for res in results:\n",
    "        print(res)\n",
    "    np.save('./Data/MPS/validation_' + featuredir + '_aug_' + '.npy', results) ## Change according to data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "With original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_names = ['hinge', 'cohinge', 'quadhinge', 'deltahinge', 'tcchinge', 'junclets']\n",
    "\n",
    "## EA and DSS\n",
    "# k = 4                                  # number of folds for cross-validation\n",
    "# n_aug = 15                             # number of augmented images per non-augmented image\n",
    "# cb_size = 15                           # codebook size\n",
    "# Cs = [1, 1, 1, 0.125, 0.125, 0.03125]  # hyper-parameters\n",
    "\n",
    "## MPS\n",
    "k = 10                                   # number of folds for cross-validation\n",
    "n_aug = 3                                # number of augmented images per non-augmented image\n",
    "cb_size = 25                             # codebook size\n",
    "Cs = [8, 0.0625, 0.125, 1, 1, 0.0625]    # hyper-parameters\n",
    "\n",
    "idx_c = 0\n",
    "\n",
    "\n",
    "for featuredir in feat_names:\n",
    "    print(featuredir)\n",
    "    # Getting feature vectores + labels\n",
    "    features, labels = get_features(featuredir, cb_size, 0)\n",
    "    features = rescale_features(features)\n",
    "\n",
    "    # Getting test set\n",
    "    test = [features[idx] for idx in test_indices]\n",
    "    test_labels = [labels[idx] for idx in test_indices]\n",
    "\n",
    "    # Getting train set\n",
    "    train = []\n",
    "    train_labels = []\n",
    "    for idx in range(len(features)):\n",
    "        if idx not in test_indices:\n",
    "            train.append(features[idx])\n",
    "            train_labels.append(labels[idx])\n",
    "\n",
    "    # Date prediction of test set\n",
    "    print(idx_c, Cs[idx_c])\n",
    "    mae_res, cs_res25, cs_res1 = plot_model(svm.SVC(kernel='linear', decision_function_shape='ovr', C=Cs[idx_c]), train, test, train_labels, test_labels)\n",
    "    print(\"MAE: %.4f  \\t CS (=25): %.4f  \\t CS(=1): %.4f \" % (mae_res, cs_res25, cs_res1))\n",
    "    print(\"%.4f,%.4f,%.4f\" % (mae_res, cs_res25, cs_res1))\n",
    "\n",
    "    idx_c += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "With augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_names = ['hinge', 'cohinge', 'quadhinge', 'deltahinge','tcchinge', 'junclets']\n",
    "\n",
    "## EA and DSS\n",
    "# k = 4                                  # number of folds for cross-validation\n",
    "# n_aug = 15                             # number of augmented images per non-augmented image\n",
    "# cb_size = 15                           # codebook size\n",
    "# Cs = [1, 1, 1, 2, 0.25, 0.25]          # hyper-parameters\n",
    "\n",
    "## MPS\n",
    "k = 10                                   # number of folds for cross-validation\n",
    "n_aug = 3                                # number of augmented images per non-augmented image\n",
    "cb_size = 25                             # codebook size\n",
    "Cs = [2, 0.0625, 0.0625, 1, 1, 0.0625]   # hyper-parameters\n",
    "\n",
    "idx_c = 0\n",
    "\n",
    "\n",
    "for featuredir in feat_names:\n",
    "    print(featuredir)\n",
    "    # Getting feature vectors + labels\n",
    "    features_norm, labels_norm, features_aug, labels_aug = get_features_aug(featuredir, cb_size, n_aug)\n",
    "    features_norm, features_aug = rescale_features_split(features_norm, features_aug)\n",
    "\n",
    "    # Test set from non-augmented data\n",
    "    test = [features_norm[idx] for idx in test_indices]\n",
    "    test_labels = [labels_norm[idx] for idx in test_indices]\n",
    "    \n",
    "    # Train set augmented data\n",
    "    train_aug = []\n",
    "    train_aug_labels = []\n",
    "    for idx in range(len(features_aug)):\n",
    "        if int(idx/n_aug) in test_indices:\n",
    "            continue\n",
    "        else:\n",
    "            train_aug.append(features_aug[idx])\n",
    "            train_aug_labels.append(labels_aug[idx])\n",
    "\n",
    "    # Train set non-augmented data\n",
    "    train_norm = []\n",
    "    train_norm_labels = []\n",
    "    for idx in range(len(features_norm)):\n",
    "        if idx not in test_indices:\n",
    "            train_norm.append(features_norm[idx])\n",
    "            train_norm_labels.append(labels_norm[idx])\n",
    "\n",
    "    # concatenating augmented and non-augmented train sets\n",
    "    train = train_norm + train_aug\n",
    "    train_labels = train_norm_labels + train_aug_labels\n",
    "    print(len(train), len(train_labels), len(train_aug))\n",
    "\n",
    "    # Date prediction on test set\n",
    "    mae_res, cs_res25, cs_res1 = plot_model(svm.SVC(kernel='linear', decision_function_shape='ovr', C=Cs[idx_c]), train, test, train_labels, test_labels)\n",
    "    print(\"MAE: %.4f  \\t CS (=25): %.4f  \\t CS(=1): %.4f \" % (mae_res, cs_res25, cs_res1))\n",
    "    print(\"%.4f,%.4f,%.4f\" % (mae_res, cs_res25, cs_res1))\n",
    "\n",
    "    idx_c += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './all/hinge/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/lisakoopmans/Documents/GitHub/Bachelor-s-thesis/experiments.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lisakoopmans/Documents/GitHub/Bachelor-s-thesis/experiments.ipynb#ch0000000?line=0'>1</a>\u001b[0m \u001b[39m# \u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lisakoopmans/Documents/GitHub/Bachelor-s-thesis/experiments.ipynb#ch0000000?line=1'>2</a>\u001b[0m aug \u001b[39m=\u001b[39m [i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(os\u001b[39m.\u001b[39;49mlistdir(\u001b[39m'\u001b[39;49m\u001b[39m./all/hinge/\u001b[39;49m\u001b[39m'\u001b[39;49m))]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lisakoopmans/Documents/GitHub/Bachelor-s-thesis/experiments.ipynb#ch0000000?line=2'>3</a>\u001b[0m origin \u001b[39m=\u001b[39m [i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(os\u001b[39m.\u001b[39mlistdir(\u001b[39m'\u001b[39m\u001b[39m./all/hinge/\u001b[39m\u001b[39m'\u001b[39m))]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lisakoopmans/Documents/GitHub/Bachelor-s-thesis/experiments.ipynb#ch0000000?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(origin))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './all/hinge/'"
     ]
    }
   ],
   "source": [
    "# number of samples per key year MPS data set\n",
    "aug = [i for i in sorted(os.listdir('./all/hinge/'))]\n",
    "origin = [i for i in sorted(os.listdir('./all/hinge/'))]\n",
    "print(len(origin))\n",
    "\n",
    "test_labels = []\n",
    "for idx in test_indices:\n",
    "    label = re.search(\"([0-9][0-9][0-9][0-9])\", origin[idx])\n",
    "    test_labels.append(label.group())\n",
    "\n",
    "for year in range(1300, 1575, 25):\n",
    "    print(test_labels.count(str(year)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [i for i in sorted(os.listdir('./Data/DSS/features/cchinge/'))]\n",
    "\n",
    "files.remove('.DS_Store')\n",
    "print(len(test_indices))\n",
    "for idx in test_indices:\n",
    "    print(files[idx])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

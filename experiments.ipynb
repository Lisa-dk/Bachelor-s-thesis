{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_absolute_error as mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions related to the model\n",
    "(i.e. k-fold cv, running the model, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cs(gt, pred, alpha):\n",
    "    count = 0\n",
    "    for i in range(len(gt)):\n",
    "        absolute_error = abs(gt[i] - pred[i])\n",
    "        if absolute_error <= alpha:\n",
    "            count += 1\n",
    "\n",
    "    return count / len(gt) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_cv(model, features, labels, k, seed):\n",
    "    mae_k = []\n",
    "    cs_k = []\n",
    "    cs_1 = []\n",
    "    # As the dataset is imbalanced --> stratified kfold + seed to get the same validation/train splits\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=seed)\n",
    "\n",
    "    for train_index, test_index in kf.split(features, labels):\n",
    "        train_features, test_features = features[train_index], features[test_index]\n",
    "        train_labels, test_labels = [labels[i] for i in train_index], [labels[i] for i in test_index]\n",
    "\n",
    "        model.fit(train_features, train_labels)\n",
    "        pred = model.predict(test_features)\n",
    "        pred = [int(i) for i in pred]\n",
    "\n",
    "        mae_k.append(mae(test_labels, pred))\n",
    "        cs_k.append(cs(test_labels, pred, 25))\n",
    "        cs_1.append(cs(test_labels, pred, 0))\n",
    "\n",
    "    return np.mean(mae_k), np.std(mae_k), np.mean(cs_k), np.std(cs_k), np.mean(cs_1), np.std(cs_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def kfold_cv_aug(model, features_norm, features_aug, labels_norm, labels_aug, k, n_aug, seed):\n",
    "    mae_k = []\n",
    "    cs_k = []\n",
    "    cs_1 = []\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=seed)\n",
    "    for train_index, test_index in tqdm.tqdm(kf.split(features_norm, labels_norm)):\n",
    "        test = [features_norm[idx] for idx in test_index]\n",
    "        test_labels = [labels_norm[idx] for idx in test_index]\n",
    "\n",
    "        train = [features_norm[idx] for idx in train_index]\n",
    "        train_labels = [labels_norm[idx] for idx in train_index]\n",
    "\n",
    "        for idx in range(len(features_aug)):\n",
    "            if int(idx/n_aug) in test_index:\n",
    "                continue\n",
    "            else:\n",
    "                train.append(features_aug[idx])\n",
    "                train_labels.append(labels_aug[idx])\n",
    "\n",
    "        model.fit(train, train_labels)\n",
    "        pred = model.predict(test)\n",
    "        pred = [int(i) for i in pred]\n",
    "\n",
    "        mae_k.append(mae(test_labels, pred))\n",
    "        cs_k.append(cs(test_labels, pred, 25))\n",
    "        cs_1.append(cs(test_labels, pred, 0))\n",
    "    return np.mean(mae_k), np.std(mae_k), np.mean(cs_k), np.std(cs_k), np.mean(cs_1), np.std(cs_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(model, train_features, test_features, train_labels, test_labels):\n",
    "    model.fit(train_features, train_labels)\n",
    "    pred = model.predict(test_features)\n",
    "    pred = [int(i) for i in pred]\n",
    "    return round(mae(test_labels, pred), 4), round(cs(test_labels, pred, 25), 4), round(cs(test_labels, pred, 1), 4)\n",
    "\n",
    "def plot_model(model, train_features, test_features, train_labels, test_labels):\n",
    "    model.fit(train_features, train_labels)\n",
    "    pred = model.predict(test_features)\n",
    "    pred = [int(i) for i in pred]\n",
    "\n",
    "    plt.scatter(test_labels, pred)\n",
    "    plt.ylabel('pred')\n",
    "    plt.xlabel('true')\n",
    "    plt.show()\n",
    "    return round(mae(test_labels, pred), 4), round(cs(test_labels, pred, 25), 4), round(cs(test_labels, pred, 1), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to process the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "HINGE = 0\n",
    "JUNC = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_features(features):\n",
    "    # rescaling features between 0 and 1\n",
    "    features = np.asarray(features)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(features)\n",
    "    data_rescaled = scaler.transform(features)\n",
    "\n",
    "    return data_rescaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_features_split(features1, features2):\n",
    "    features1 = np.array(features1)\n",
    "    features2 = np.array(features2)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(np.concatenate((features1, features2), axis=0))\n",
    "    data_rescaled1 = scaler.transform(features1)\n",
    "    data_rescaled2 = scaler.transform(features2)\n",
    "    return data_rescaled1, data_rescaled2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features2(feature_dir, hinge_or_junc, n_aug):\n",
    "    features = []\n",
    "    labels = []\n",
    "    count = 0\n",
    "    print(n_aug, feature_dir)\n",
    "\n",
    "    for file in sorted(os.listdir(feature_dir)):\n",
    "        aug_num = re.search(\"(_[0-9]?[0-9].p)\", file)\n",
    "\n",
    "        if aug_num is not None:\n",
    "            aug_num = re.search(\"([0-9]?[0-9])\", aug_num.group())\n",
    "        if aug_num is None or (aug_num is not None and int(aug_num .group()) <= n_aug):\n",
    "            if file != \".DS_Store\" and not os.path.isdir(feature_dir + '/' + file):\n",
    "                f = open(feature_dir + \"/\" + file)\n",
    "                for line in f.readlines():\n",
    "                    line = line.rstrip().split(\" \")\n",
    "                    if hinge_or_junc == HINGE:\n",
    "                        features.append(line[2:])\n",
    "                    elif hinge_or_junc == JUNC:\n",
    "                        features.append([float(el) for el in line])\n",
    "                        count += 1\n",
    "\n",
    "                    label = re.search(\"([0-9][0-9][0-9][0-9])\", file) #MPS\n",
    "                    #label = re.search(\"(-?[0-9][0-9][0-9])\", file) #DSS\n",
    "                    labels.append(int(label.group()))\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(featuredir, size, n_aug):\n",
    "    if featuredir != 'junclets' and featuredir != 'test/junclets':\n",
    "        prefix = './Data/DSS/features/'\n",
    "        features, labels = get_features2(prefix + featuredir, HINGE, n_aug)\n",
    "    elif featuredir == 'junclets':\n",
    "        #prefix = './Data/DSS/features/' + featuredir + '/size_' + str(size) + '/'\n",
    "        features, labels = get_features2(prefix, JUNC, n_aug)\n",
    "    return features, labels\n",
    "\n",
    "def get_features_aug(featuredir, size, n_aug):\n",
    "    if featuredir != 'junclets':\n",
    "        prefix = './Data/DSS/features/'\n",
    "        features_norm, labels_norm = get_features2(prefix + featuredir, HINGE, n_aug)\n",
    "        features_aug, labels_aug = get_features2(prefix + 'features_aug_15/' + featuredir + '_aug', HINGE, n_aug)\n",
    "    else:\n",
    "        #prefix = './Data/DSS/junc_aug/features/' + featuredir + '/size_' + str(size) + '/'\n",
    "        prefix = './tfsom/MPS/all/junclets/size_' + str(size) + '/'\n",
    "        #features_norm, labels_norm = get_features2('./Data/DSS/features/'+ featuredir + '/size_' + str(size) + '/', JUNC, n_aug)\n",
    "        features_norm, labels_norm = get_features2(prefix, JUNC, n_aug)\n",
    "        #prefix = './Data/DSS/junc_aug/features_aug/' + featuredir + '/size_' + str(size) + '/'\n",
    "        prefix = './tfsom/MPS/all/junclets_aug/size_' + str(size) + '/'\n",
    "        features_aug, labels_aug = get_features2(prefix, JUNC, n_aug)\n",
    "\n",
    "    return features_norm, labels_norm, features_aug, labels_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting indices for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MPS\n",
    "size_data = 3267\n",
    "test_size = 0.1 #as a fraction\n",
    "test_indices = np.random.choice(np.array([i for i in range(size_data)]), int(size_data * test_size), replace=False)\n",
    "np.save('./test_indices.npy', test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EA and DSS\n",
    "idx = 0\n",
    "for file in sorted(os.listdir('./Data/DSS/DSS_jpg_re/')):\n",
    "    label = re.search(\"(-?[0-9][0-9][0-9])\", file)\n",
    "    print(label.group(), idx)\n",
    "    idx += 1\n",
    "\n",
    "np.save('./Data/DSS/test_indices.npy', [0, 5, 6, 16, 17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_indices = np.load('./Data/DSS/test_indices.npy')\n",
    "test_indices = np.load('./tfsom/MPS/test_indices.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Hyperparameters\n",
    "Uses K-fold cross validation with k = 10 for MPS and k = 4 for EA and DSS data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "With original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_names = ['hinge', 'cohinge', 'quadhinge', 'deltahinge', 'tcchinge']\n",
    "\n",
    "k = 4 ## EA and DSS\n",
    "# k = 10 ## MPS\n",
    "Cs = [pow(2, n) for n in range(-7, 10, 1)]\n",
    "seeds = [0, 50, 100, 150, 200, 250]\n",
    "\n",
    "for featuredir in feat_names:\n",
    "    print(featuredir)\n",
    "    features, labels = get_features(featuredir, 0, 0)\n",
    "    features = rescale_features(features)\n",
    "    test = [features[idx] for idx in test_indices]\n",
    "    test_labels = [labels[idx] for idx in test_indices]\n",
    "\n",
    "    train = []\n",
    "    train_labels = []\n",
    "    for idx in range(len(features)):\n",
    "        if idx not in test_indices:\n",
    "            train.append(features[idx])\n",
    "            train_labels.append(labels[idx])\n",
    "\n",
    "    results = [[0, 0, 0, 0, 0, 0, 0] for i in range(len(Cs))]\n",
    "\n",
    "    for seed in seeds:\n",
    "        for c_idx in range(len(Cs)):\n",
    "            results[c_idx][0] = Cs[c_idx]\n",
    "            clf = kfold_cv(svm.SVC(kernel='linear', decision_function_shape='ovr', C=Cs[c_idx]), np.array(train), np.array(train_labels), k, seed)\n",
    "            for res_idx in range(len(clf)):\n",
    "                results[c_idx][res_idx + 1] += clf[res_idx]\n",
    "    \n",
    "    for c_idx in range(len(results)):\n",
    "        for res_idx in range(1, len(results[c_idx])):\n",
    "            results[c_idx][res_idx] = results[c_idx][res_idx]/len(seeds)\n",
    "\n",
    "    for res in results:\n",
    "        print(res)\n",
    "    np.save('./Data/DSS/validation_' + featuredir + '.npy', results) ## Change according to data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "featuredir = 'junclets'\n",
    "\n",
    "k = 4 ## EA and DSS\n",
    "# k = 10 ## MPS\n",
    "Cs = [pow(2, n) for n in range(-7,10, 1)]\n",
    "seeds = [0, 50, 100, 150, 200, 250]\n",
    "\n",
    "for cb_size in range(5, 35, 5):\n",
    "    print(cb_size)\n",
    "    features, labels = get_features(featuredir, cb_size, 0)\n",
    "    features = rescale_features(features)\n",
    "    test = [features[idx] for idx in test_indices]\n",
    "    test_labels = [labels[idx] for idx in test_indices]\n",
    "\n",
    "    train = []\n",
    "    train_labels = []\n",
    "    for idx in range(len(features)):\n",
    "        if idx not in test_indices:\n",
    "            train.append(features[idx])\n",
    "            train_labels.append(labels[idx])\n",
    "\n",
    "    results = [[0, 0, 0, 0, 0, 0, 0] for i in range(len(Cs))]\n",
    "    for seed in seeds:\n",
    "        for c_idx in range(len(Cs)):\n",
    "            results[c_idx][0] = Cs[c_idx]\n",
    "            clf = kfold_cv(svm.SVC(kernel='linear', decision_function_shape='ovr', C=Cs[c_idx]), np.array(train), np.array(train_labels), k, seed)\n",
    "            for res_idx in range(len(clf)):\n",
    "                results[c_idx][res_idx + 1] += clf[res_idx]\n",
    "    \n",
    "    for c_idx in range(len(results)):\n",
    "        for res_idx in range(1, len(results[c_idx])):\n",
    "            results[c_idx][res_idx] = results[c_idx][res_idx]/len(seeds)\n",
    "\n",
    "    for res in results:\n",
    "        print(res)\n",
    "    np.save('./Data/DSS/validation_' + featuredir + '_' + str(cb_size) + '.npy', results) ## Change according to data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "With augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_names = ['hinge', 'cohinge', 'quadhinge', 'deltahinge', 'tcchinge', 'junclets']\n",
    "\n",
    "## EA and DSS\n",
    "# k = 4\n",
    "# n_aug = 15\n",
    "# cb_size = 15\n",
    "\n",
    "## MPS\n",
    "k = 10\n",
    "n_aug = 3\n",
    "cb_size = 25\n",
    "\n",
    "Cs = [pow(2, n) for n in range(-7,10, 1)]\n",
    "seeds = [0, 50, 100, 150, 200, 250]\n",
    "\n",
    "\n",
    "for featuredir in feat_names:\n",
    "    print(featuredir)\n",
    "    features_norm, labels_norm, features_aug, labels_aug = get_features_aug(featuredir, cb_size, n_aug)\n",
    "    features_norm, features_aug = rescale_features_split(features_norm, features_aug)\n",
    "    test = [features_norm[idx] for idx in test_indices]\n",
    "    test_labels = [labels_norm[idx] for idx in test_indices]\n",
    "\n",
    "    train_aug = []\n",
    "    train_aug_labels = []\n",
    "    for idx in range(len(features_aug)):\n",
    "        if int(idx/n_aug) in test_indices:\n",
    "            continue\n",
    "        else:\n",
    "            train_aug.append(features_aug[idx])\n",
    "            train_aug_labels.append(labels_aug[idx])\n",
    "\n",
    "    train_norm = []\n",
    "    train_norm_labels = []\n",
    "    for idx in range(len(features_norm)):\n",
    "        if idx not in test_indices:\n",
    "            train_norm.append(features_norm[idx])\n",
    "            train_norm_labels.append(labels_norm[idx])\n",
    "            \n",
    "    results = [[0, 0, 0, 0, 0, 0, 0] for i in range(len(Cs))]\n",
    "\n",
    "    for seed in tqdm.tqdm(seeds):\n",
    "        print(seed)\n",
    "        for c_idx in range(len(Cs)):\n",
    "            print(Cs[c_idx])\n",
    "            results[c_idx][0] = Cs[c_idx]\n",
    "            clf = kfold_cv_aug(svm.SVC(kernel='linear', decision_function_shape='ovr', C=Cs[c_idx]), train_norm, train_aug, train_norm_labels, train_aug_labels, k, n_aug, seed=seed)\n",
    "            for res_idx in range(len(clf)):\n",
    "                results[c_idx][res_idx + 1] += clf[res_idx]\n",
    "    \n",
    "    for c_idx in range(len(results)):\n",
    "        for res_idx in range(1, len(results[c_idx])):\n",
    "            results[c_idx][res_idx] = results[c_idx][res_idx]/len(seeds)\n",
    "\n",
    "    for res in results:\n",
    "        print(res)\n",
    "    np.save('./Data/MPS/validation_' + featuredir + '_aug_' + '.npy', results) ## Change according to data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "With original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_names = ['hinge', 'cohinge', 'quadhinge', 'deltahinge', 'tcchinge', 'junclets']\n",
    "\n",
    "## EA and DSS\n",
    "# k = 4\n",
    "# n_aug = 15\n",
    "# cb_size = 15\n",
    "# Cs = [1, 1, 1, 0.125, 0.125, 0.03125]\n",
    "\n",
    "## MPS\n",
    "k = 10\n",
    "n_aug = 3\n",
    "cb_size = 25\n",
    "Cs = [8, 0.0625, 0.125, 1, 1, 0.0625]\n",
    "\n",
    "idx_c = 0\n",
    "\n",
    "\n",
    "for featuredir in feat_names:\n",
    "    print(featuredir)\n",
    "    features, labels = get_features(featuredir, cb_size, 0)\n",
    "    features = rescale_features(features)\n",
    "    test = [features[idx] for idx in test_indices]\n",
    "    test_labels = [labels[idx] for idx in test_indices]\n",
    "\n",
    "    train = []\n",
    "    train_labels = []\n",
    "    for idx in range(len(features)):\n",
    "        if idx not in test_indices:\n",
    "            train.append(features[idx])\n",
    "            train_labels.append(labels[idx])\n",
    "\n",
    "    print(idx_c, Cs[idx_c])\n",
    "    mae_res, cs_res25, cs_res1 = plot_model(svm.SVC(kernel='linear', decision_function_shape='ovr', C=Cs[idx_c]), train, test, train_labels, test_labels)\n",
    "    print(\"MAE: %.4f  \\t CS (=25): %.4f  \\t CS(=1): %.4f \" % (mae_res, cs_res25, cs_res1))\n",
    "    print(\"%.4f,%.4f,%.4f\" % (mae_res, cs_res25, cs_res1))\n",
    "\n",
    "    idx_c += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "With augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_names = ['hinge', 'cohinge', 'quadhinge', 'deltahinge','tcchinge', 'junclets']\n",
    "\n",
    "## EA and DSS\n",
    "# k = 4\n",
    "# n_aug = 15\n",
    "# cb_size = 15\n",
    "# Cs = [1, 1, 1, 2, 0.25, 0.25]\n",
    "\n",
    "## MPS\n",
    "k = 10\n",
    "n_aug = 3\n",
    "cb_size = 25\n",
    "Cs = [2, 0.0625, 0.0625, 1, 1, 0.0625]\n",
    "\n",
    "idx_c = 0\n",
    "\n",
    "\n",
    "for featuredir in feat_names:\n",
    "    print(featuredir)\n",
    "    features_norm, labels_norm, features_aug, labels_aug = get_features_aug(featuredir, cb_size, n_aug)\n",
    "    features_norm, features_aug = rescale_features_split(features_norm, features_aug)\n",
    "\n",
    "    test = [features_norm[idx] for idx in test_indices]\n",
    "    test_labels = [labels_norm[idx] for idx in test_indices]\n",
    "    \n",
    "    train_aug = []\n",
    "    train_aug_labels = []\n",
    "    for idx in range(len(features_aug)):\n",
    "        if int(idx/n_aug) in test_indices:\n",
    "            continue\n",
    "        else:\n",
    "            train_aug.append(features_aug[idx])\n",
    "            train_aug_labels.append(labels_aug[idx])\n",
    "\n",
    "    train_norm = []\n",
    "    train_norm_labels = []\n",
    "    for idx in range(len(features_norm)):\n",
    "        if idx not in test_indices:\n",
    "            train_norm.append(features_norm[idx])\n",
    "            train_norm_labels.append(labels_norm[idx])\n",
    "\n",
    "    train = train_norm + train_aug\n",
    "    train_labels = train_norm_labels + train_aug_labels\n",
    "    print(len(train), len(train_labels), len(train_aug))\n",
    "\n",
    "    mae_res, cs_res25, cs_res1 = plot_model(svm.SVC(kernel='linear', decision_function_shape='ovr', C=Cs[idx_c]), train, test, train_labels, test_labels)\n",
    "    print(\"MAE: %.4f  \\t CS (=25): %.4f  \\t CS(=1): %.4f \" % (mae_res, cs_res25, cs_res1))\n",
    "    print(\"%.4f,%.4f,%.4f\" % (mae_res, cs_res25, cs_res1))\n",
    "\n",
    "    idx_c += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "aug = [i for i in sorted(os.listdir('./all/hinge/'))]\n",
    "origin = [i for i in sorted(os.listdir('./all/hinge/'))]\n",
    "print(len(origin))\n",
    "\n",
    "test_labels = []\n",
    "for idx in test_indices:\n",
    "    label = re.search(\"([0-9][0-9][0-9][0-9])\", origin[idx])\n",
    "    test_labels.append(label.group())\n",
    "\n",
    "for year in range(1300, 1575, 25):\n",
    "    print(test_labels.count(str(year)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [i for i in sorted(os.listdir('./Data/DSS/features/cchinge/'))]\n",
    "\n",
    "files.remove('.DS_Store')\n",
    "print(len(test_indices))\n",
    "for idx in test_indices:\n",
    "    print(files[idx])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
